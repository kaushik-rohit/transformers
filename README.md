# transformers

Learning to code transformers from scratch in pytorch following Umar Jamil.

Also using this to understand vLLM architecture so practising some exercises on PagedAttention and
KV cache memory management.

